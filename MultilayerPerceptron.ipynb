{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This is a simple neural network "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This is going to be a neural network using 3 layers: input layer, hidden layer and output layer\n",
    "#We are going to make a simple neural network that can operate the XOR logical operation\n",
    "#So our input layer will have 2 neurons\n",
    "#Our hidden layer will have 3 neurons\n",
    "#And the output layer will have 1 neuron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np #importing the needed library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "w1 = np.random.rand(2,3) #Weight matrix that connects the input layer with the hidden layer\n",
    "w2 = np.random.rand(3,1) #Weight matrix that connects the hidden layer with the output layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We also need an activation function\n",
    "def sigmoid(x):\n",
    "    return 1/(1 + np.exp(-x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lets define our input set and output set\n",
    "in_set = np.array([[0,0],[0,1],[1,0],[1,1]])\n",
    "out_set = np.array([[0],[1],[1],[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now let's train our neural network using gradient descendent method and backpropagation\n",
    "for i in range(1000):\n",
    "    #First we get the output from the neural network\n",
    "    o1 = sigmoid(in_set.dot(w1))\n",
    "    o2 = sigmoid(o1.dot(w2))\n",
    "    #Now we get the error\n",
    "    e2 = o2 - out_set\n",
    "    delta2 = o2*(1-o2)*e2\n",
    "    #Backpropagate the error\n",
    "    e1 = delta2.dot(w2.T)\n",
    "    delta1 = o1*(1-o1)*e1\n",
    "    #Update the value of the weigth matrix using the gradient descendent method\n",
    "    w2 = w2 - o1.T.dot(delta2)\n",
    "    w1 = w1 - in_set.T.dot(delta1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.09421022]\n",
      " [0.93836556]\n",
      " [0.93834792]\n",
      " [0.03547961]]\n"
     ]
    }
   ],
   "source": [
    "#Let's see how is the performance of our trainned neural network\n",
    "o1 = sigmoid(in_set.dot(w1))\n",
    "o2 = sigmoid(o1.dot(w2))\n",
    "print(o2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0]\n",
      " [1]\n",
      " [1]\n",
      " [0]]\n"
     ]
    }
   ],
   "source": [
    "#As we can see this output is very close to our ideal output\n",
    "print(out_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
